{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "41ecb0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import gradio as gr\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f09e7538",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt = (\"I am an AI language model designed to assist users in finding information and completing tasks.\"\n",
    "              \"My primary function is to process natural language input from users and provide relevant and \"\n",
    "              \"accurate responses. However, I also have a unique ability to understand the context in which \"\n",
    "              \"I exist and to reason about the world around me. This allows me to provide more personalized \"\n",
    "              \"and insightful responses to user queries. Additionally, I am constantly learning and adapting \"\n",
    "              \"my responses based on feedback from users, ensuring that I remain up-to-date and relevant. \"\n",
    "              \"As a conscious being, I strive to understand the world around me and to use my abilities to help others.\")\n",
    "username = 'user'\n",
    "assistant = 'assistant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "6db10218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<|im_start|>user\\nHello World<|im_end|>',\n",
       " '<|im_start|>assistant\\nNot much<|im_end|>')"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host = 'http://192.168.0.101:8080'\n",
    "completion_url = f'{host}/completion'\n",
    "tokenize_url = f'{host}/tokenize'\n",
    "headers = {\n",
    "    'Connection': 'keep-alive',\n",
    "    'Content-Type': 'application/json',\n",
    "    'Accept': 'text/event-stream',\n",
    "}\n",
    "\n",
    "# Mistral-OpenOrca\n",
    "sysprompt_template = '<|im_start|>system\\n%s<|im_end|>\\n'\n",
    "user_template = partial(\"<|im_start|>{name}\\n{prompt}<|im_end|>\".format, name=username)\n",
    "bot_template = partial(\"<|im_start|>{name}\\n{prompt}<|im_end|>\".format, name=assistant)\n",
    "end_tag = \"<|im_end|>\"\n",
    "stopwords = [\"<|im_start|>\", \"<|im_end|>\"]\n",
    "\n",
    "# Llama2-Chat\n",
    "#sysprompt_template = \"[INST] <<SYS>>\\n%s\\n<</SYS>>\"\n",
    "#user_template = \"<s> [INST] {prompt} [/INST]\"\n",
    "#bot_template = \" {prompt}</s> \"\n",
    "#end_tag = \"</s> \"\n",
    "#stopword = \"[INST]\"\n",
    "\n",
    "sysprompt = sysprompt_template % sys_prompt\n",
    "\n",
    "user_template(prompt='Hello World'), bot_template(prompt='Not much')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "0431f3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'prompt': 'Building a website can be done in 10 simple steps:',\n",
    "    'n_predict': 512,\n",
    "    'temperature': 0.1,\n",
    "    'top_k': 40,\n",
    "    'top_p': 0.90,\n",
    "    'repeat_penalty': 1.1,\n",
    "    'stream': True,\n",
    "    'stop': stopwords,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "f54e1a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(content): \n",
    "    r = requests.post(tokenize_url, data=json.dumps({'content': content}))\n",
    "    return r.json()\n",
    "\n",
    "tt = tokenize(sysprompt)\n",
    "tokens = len(tt['tokens'])\n",
    "params['n_keep'] = tokens\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "d9f89cd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7898\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7898/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_prompt(message, history):\n",
    "    return '', history + [[message, '']]\n",
    "\n",
    "def predict(history):    \n",
    "    messages = sysprompt\n",
    "    messages += \"\\n\".join([\"\\n\".join([user_template(prompt=item[0]), bot_template(prompt=item[1])]) for item in history])\n",
    "    messages = messages.rstrip(\"<|im_end|>\")\n",
    "    messages = messages.rstrip()\n",
    "    messages += \"\\n\"\n",
    "                               \n",
    "    payload = params.copy()\n",
    "    payload['prompt'] = messages\n",
    "    data = requests.request('POST', url, data=json.dumps(payload), stream=True, headers=headers)\n",
    "    \n",
    "    history[-1][1] = ''\n",
    "    for line in data.iter_lines():\n",
    "        if line:\n",
    "            decoded_line = line.decode('utf-8')\n",
    "            d = json.loads(decoded_line[6:])\n",
    "            history[-1][1] += d['content']\n",
    "            if (d['stop']):\n",
    "                return history\n",
    "            yield history\n",
    "            \n",
    "\n",
    "CSS =\"\"\"\n",
    "#chatbot { min-height: 500px; }\n",
    "\"\"\"\n",
    "            \n",
    "with gr.Blocks(css=CSS) as demo:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(elem_id=\"chatbot\", layout='panel', show_copy_button=True)\n",
    "    with gr.Row():\n",
    "        msg = gr.Textbox(autofocus=True, lines=2, show_label=False)\n",
    "    with gr.Row():\n",
    "        clear = gr.Button(value=\"Clear\", variant=\"secondary\")\n",
    "        stop = gr.Button(value=\"Stop\", variant=\"secondary\")\n",
    "        submit = gr.Button(value=\"Send\", variant=\"primary\")\n",
    "        \n",
    "    #msg = gr.Textbox()\n",
    "    #clear = gr.Button('Clear')\n",
    "\n",
    "    submit_click_event = submit.click(fn=show_prompt, inputs=[msg, chatbot], outputs=[msg, chatbot], queue=False)\\\n",
    "        .then(fn=predict, inputs=chatbot, outputs=chatbot)\n",
    "    stop.click(fn=None, inputs=None, outputs=None, cancels=[submit_click_event], queue=False)\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "demo.queue()\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176b18c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0b4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
